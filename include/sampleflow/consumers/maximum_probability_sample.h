// ---------------------------------------------------------------------
//
// Copyright (C) 2019 by the SampleFlow authors.
//
// This file is part of the SampleFlow library.
//
// The deal.II library is free software; you can use it, redistribute
// it, and/or modify it under the terms of the GNU Lesser General
// Public License as published by the Free Software Foundation; either
// version 2.1 of the License, or (at your option) any later version.
// The full text of the license can be found in the file LICENSE.md at
// the top level directory of deal.II.
//
// ---------------------------------------------------------------------

#ifndef SAMPLEFLOW_CONSUMERS_MAXIMUM_PROBABILITY_SAMPLE_H
#define SAMPLEFLOW_CONSUMERS_MAXIMUM_PROBABILITY_SAMPLE_H

#include <sampleflow/consumer.h>
#include <mutex>


namespace SampleFlow
{
  namespace Consumers
  {
    /**
     * A Consumer class that implements computing the running mean value
     * over all samples seen so far. The last value so computed can be
     * obtained by calling the get() function.
     *
     * This class uses the following formula to update the mean $\bar x_k$
     * after seeing $k$ samples $x_1\ldots x_k$:
     * @f{align*}{
     *      \bar x_1 &= x_1,
     *   \\ \bar x_k &= \bar x_{k-1} + \frac{1}{k} (x_k - \bar x_{k-1}).
     * @f}
     *
     * This formula can be derived by considering the following relationships:
     * @f{align*}{
     *      \bar x_k &= \frac{1}{k} \sum_{j=1}^k x_j
     *      \\       &= \frac{1}{k} \left( \sum_{j=1}^{k-1} x_j + x_k \right)
     *      \\       &= \frac{1}{k} \left( (k-1)\bar x_{k-1} + x_k \right)
     *      \\       &= \frac{k-1}{k} \bar x_{k-1} + \frac{1}{k} x_k
     *      \\       &= \bar x_{k-1} - \frac{1}{k} \bar x_{k-1} + \frac{1}{k} x_k
     *      \\       &= \bar x_{k-1} + \frac{1}{k} (x_k - \bar x_{k-1}).
     * @f}
     *
     *
     * ### Threading model ###
     *
     * The implementation of this class is thread-safe, i.e., its
     * consume() member function can be called concurrently and from multiple
     * threads.
     *
     *
     * @tparam InputType The C++ type used for the samples $x_k$. In
     *   order to compute mean values, this type must allow taking
     *   the sum of samples, and division by a scalar.
     */
    template <typename InputType>
    class MaximumProbabilitySample : public Consumer<InputType>
    {
      public:
        /**
         * The type of the information generated by this class. Here, this
         * is of course InputType, the data type used to represent samples.
         */
        using value_type = InputType;

        /**
         * Constructor.
         */
        MaximumProbabilitySample ();

        /**
         * Process one sample by checking whether it has a higher probability
         * (log likelihoood) than the previously most likely one. If so, store
         * it so that it can later be returned by the get() function.
         *
         * @param[in] sample The sample to process.
         * @param[in] aux_data Auxiliary data about this sample. The current
         *   class checks whether a sample has information named
         *   "relative log likelihood" attached to it (see, for example, the
         *   Producers::MetropolisHastings class) and evaluates its value.
         *   All other attributes are ignored.
         */
        virtual
        void
        consume (InputType     sample,
                 AuxiliaryData aux_data) override;

        /**
         * A function that returns the mean value computed from the samples
         * seen so far. If no samples have been processed so far, then a
         * default-constructed object of type InputType will be returned.
         *
         * @return The computed mean value.
         */
        value_type
        get () const;

      private:
        /**
         * A mutex used to lock access to all member variables when running
         * on multiple threads.
         */
        mutable std::mutex mutex;

        /**
         * The currently most likely sample
         */
        InputType          current_most_likely_sample;

        /**
         * The log likelihood of the currently most likely sample. If we have
         * not seen any sample at all so far, then this value is set to
         * std::numeric_limits<double>::lowest().
         */
        double             current_highest_log_likelihood;
    };



    template <typename InputType>
    MaximumProbabilitySample<InputType>::
    MaximumProbabilitySample ()
      :
      current_most_likely_sample (),
      current_highest_log_likelihood(std::numeric_limits<double>::lowest())
    {}



    template <typename InputType>
    void
    MaximumProbabilitySample<InputType>::
    consume (InputType sample, AuxiliaryData aux_data)
    {
      // Let's see first if the sample provided has the log likelihood
      // attribute we would like to evaluate
      if (aux_data.find ("relative log likelihood") != aux_data.end())
        {
          const double log_likelihood = boost::any_cast<double>(aux_data["relative log likelihood"]);

          std::lock_guard<std::mutex> lock(mutex);

          // Check if we have seen any sample at all so far
          if (current_highest_log_likelihood == std::numeric_limits<double>::lowest())
            {
              current_most_likely_sample = std::move (sample);
              current_highest_log_likelihood = log_likelihood;
            }
          else
            {
              // We had seen samples before, so check whether this one is better.
              if (current_highest_log_likelihood < log_likelihood)
                {
                  current_most_likely_sample = std::move (sample);
                  current_highest_log_likelihood = log_likelihood;
                }
            }
        }
    }



    template <typename InputType>
    typename MaximumProbabilitySample<InputType>::value_type
    MaximumProbabilitySample<InputType>::
    get () const
    {
      std::lock_guard<std::mutex> lock(mutex);

      return current_most_likely_sample;
    }

  }
}

#endif
